{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546cbab0-d4f2-41f4-8686-78935992dee9",
   "metadata": {},
   "source": [
    "# **0. 참고자료**\n",
    "## **0-1. 도서**\n",
    "   - 한빛 미디어 | 오를레앙 제롱 저, 박해선 역 - 핸즈온 머신러닝\n",
    "\n",
    "## **0-2. 웹사이트**\n",
    "- char :: 머신러닝 - 군집 | [[블로그 링크]](https://charstring.tistory.com/425) \n",
    "\n",
    "# **1. 머신러닝이란**\n",
    "- 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다. - 아서 새뮤얼  \n",
    "\n",
    "## **1-1. 왜 머신러닝을 사용하는가**\n",
    "- 메일의 제목을 보고 스팸 필터를 만든다고 가정하였을 때\n",
    "- 전통적인 프로그래밍 기법을 사용  \n",
    "→ 작성해야하는 규칙이 점점 길과 복잡해져 비효율적으로 동작하고, 유지보수하기 힘들어진다.  \n",
    "\n",
    "- 머신러닝 기법을 사용  \n",
    "→ 스팸 메일에서 자주 나타나는 <span style=\"color: orange\"><b>패턴을 감지</b></span>하여 어떤 단어와 구절이 스팸 메일을 판단하는 데 좋은 기준인지 자동으로 학습  \n",
    "\n",
    "<span style=\"color:orange\"><b>< ! > 머신러닝 기술을 적용하여 대용량의 데이터를 분석하여 패턴을 발견하는 것을 <span style=\"color:red\">데이터 마이닝(data mining)</span>이라 한다.</b></span>  \n",
    "    \n",
    "## **1-2. 머신러닝 시스템의 종류**  \n",
    "### 1-2.1. 지도학습과 비지도 학습\n",
    "#### **(1) 지도 학습 (Supervised Learning)**  \n",
    "- 학습하고자 하는 알고리즘에 주입하는 훈련 데이터에 <span style=\"color:orange\"><b>레이블 (label)</b></span>이라는 원하는 답을 포함한다.  \n",
    "- <span style=\"color:orange\"><b>분류 (classification)</b></span>와 <span style=\"color:orange\"><b>회귀 (regression)</b></span>가 전형적인 지도학습이다.  \n",
    "    \n",
    "<span style=\"color: orange\"><b>< ! > 머신러닝에서 <span style=\"color: red\">속성 (attribute)</span>은 데이터 타입을 의미한다.</b></span>\n",
    "<span style=\"color: orange\"><b></b></span>  \n",
    "<span style=\"color: orange\"><b>< ! > 머신러닝에서 <span style=\"color: red\">특성 (feature)</span>는 일반적으로 속성과 값이 합쳐진 것을 의미한다.</b></span>\n",
    "<span style=\"color: orange\"><b></b></span>  \n",
    "    \n",
    "- **분류 (Classification)**  \n",
    "→ 주어진 데이터를 클래스 별로 구별해가는 과정   \n",
    "\n",
    "- **회귀 (Regression)**  \n",
    "    → 특성을 사용하여 <span style=\"color:orange\"><b>타깃 (Target)</b></span> 수치를 예측하는 과정  \n",
    "    \n",
    "- 일부 회귀 알고리즘은 분류에 사용할 수 있고, 반대로 일부 분류 알고리즘을 회귀에 사용할 수 있다.  \n",
    "\n",
    "#### **(1)-1. 지도학습 알고리즘  예시**  \n",
    "    1) k-최근접 이웃 (k-Nearest Neighbors | kNN)  \n",
    "    2) 선형 회귀 (linear regression)  \n",
    "    3) 로지스틱 회귀 (logistic regression)  \n",
    "    4) 서포트 벡터 머신 (Support Vector Machine | SVM)  \n",
    "    5) 결정 트리 (Decision tree)  \n",
    "    6) 랜덤 포레스트 (random forest)  \n",
    "    7) 신경망 (Neural Network | NN)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d95492-4d2e-4f88-b146-529eef0c1e19",
   "metadata": {},
   "source": [
    "#### **(2) 비지도 학습 (Unsupervised Learning)**  \n",
    "- 지도 학습과 달리 훈련 데이터에 레이블이 없이 학습해야 함.\n",
    "\n",
    "#### **(2)-1. 비지도학습 알고리즘  예시**  \n",
    "    1)  군집 (clustering)  \n",
    "        1)-1. k-평균 (k-means)   \n",
    "        1)-2. DBSCAN  \n",
    "        1)-3. 계층 군집 분석(Hierarchical Cluseter Analysis | HCA)  \n",
    "        1)-4. 이상치 탐지(outlier detection)와 특이치 탐지(novelty detection)    \n",
    "        1)-5. 원-클래스 SVM (one-class SVM)  \n",
    "        1)-6. 아이솔레이션 포레스트 (isolation forest)  \n",
    "        \n",
    "    2) 시각화 (visualization)와 차원 축소 (dimensionality reduction)\n",
    "        2)-1. 주성분 분석 (Principal Component Analysis | PCA)  \n",
    "        2)-2. 커널 PCA (kernel PCA)  \n",
    "        2)-3. 지역적 선형 임베딩 (Locally Linear Embedding)  \n",
    "        2)-4. t-SNE (t-distributed Stochastic Neighbor Embedding)  \n",
    "        \n",
    "    3) 연관 규칙 학습 (association rule learning)  \n",
    "        3)-1. 어프라이어리 (Apriori)  \n",
    "        3)-2. 이클렛 (Eclat)  \n",
    "\n",
    "- **군집 (Clustering)**  \n",
    "→ 대상을 군집 (Clustering)이라 불리는 상대적으로 동질적인 집단으로 분류하는 기법  \n",
    "→ <span style=\"color:orange\"><b>계층 군집 (Hierarchical Clustering)</b></span>알고리즘을 사용하면 각 그룹을 더 작은 그룹으로 세분화 할 수 있다.\n",
    "\n",
    "- **시각화 (Visualization)**  \n",
    "→ 레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D 표현을 만들어줌.  \n",
    "→ 알고리즘은 가능한 한 구조를 그대로 유지하려 하므로 데이터가 어떻게 조작되어 있는지 이해할 수 있다.  \n",
    "→ 비슷한 작업으로는 많은 정보를 잃지 않으며 데이터를 간소화하는 <span style=\"color: orange\"><b>차원 축소</b></span>가 있다.  \n",
    "\n",
    "<span style=\"color: orange\"><b>< ! > 차원축소 기법 중 하나는 상관관계가 있는 여러 특성을 하나로 합치는 것이 있는데, 이를 <span style=\"color: red\">특성 추출 (Feature Extraction)</span>이라 한다.</b></span>  \n",
    "<span style=\"color: orange\"><b>< ! >지도 학습 같은 머신러닝 알고리즘에 데이터를 주입하기 전에 차원 축소 알고리즘을 사용하여 데이터의 차원을 줄이는 것이 유용할 때가 많다.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;→ 실행 속도가 빨라지고, 디스크와 메모리를 차지아는 공간도 줄고 성능이 향상될 수도 있다.\n",
    "</b></span>  \n",
    "    \n",
    "- **이상치 탐지(Outlier Detection | Anomaly Detection)**  \n",
    "→ 훈련하는 동안 대부분 정상 샘플을 만나 이상치를 인식하도록 훈련됨.  \n",
    "→ 새로운 샘플을 보고 정상 데이터인지 이상치인지 판단함.  \n",
    "→ 비슷한 작업으로 <span style=\"color: orange\"><b>특이치 탐지</b></span>가 있다.  \n",
    "→ 특이치 탐지는 훈련 세트에 있는 모든 샘플과 달라 보이는 새로운 샘플을 탐지하는 것이 목적이다.   \n",
    "\n",
    "- **연관 규칙 학습 (Association rule learning)**  \n",
    "→ 대량의 데이터에서 특성 간 관계를 찾는 작업  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a54098f-f9f5-41c0-ba3b-b54468230efa",
   "metadata": {},
   "source": [
    "#### **(3) 준지도 학습 (Semi-supervised Learning)**  \n",
    "- 데이터에 레이블을 달기에 많은 시간과 비용이 소모되어 일반적으로 레이블이 없는 샘플이 많고 레이블된 샘플이 적다.  \n",
    "- 준지도 학습에서는 일부만 레이블이 있는 데이터를 학습시키는데 사용된다.  \n",
    "- 대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조합으로 이루어져 있다.  \n",
    "- 준지도 학습의 일종인 <span style=\"color:orange\"><b>심층 신뢰 신경망 (Deep Belief Network | DBN)</b></span>은 여러 겺으로 쌓은 <span style=\"color:orange\"><b>제한된 볼츠만 머신(Restricted Boltzmann Machine)</b></span>이라 불리는 비지도 학습에 기초한다.  \n",
    "\n",
    "#### **(4) 강화 학습 (Reinforcement Learning)**  \n",
    "- 알고리즘이 학습 하는 시스템을 <span style=\"color:orange\"><b>에이전트 (Agent)</b></span>라 부른다.\n",
    "- <span style=\"color:orange\"><b>환경 (Environment)</b></span>을 관찰하여 <span style=\"color:orange\"><b>행동 (Action)</b></span>을 실행하고 그 결과로 <span style=\"color:orange\"><b>보상 (Reward)</b></span> 혹은 <span style=\"color:orange\"><b>벌점 (Panalty)</b></span>를 받는다.  \n",
    "- 시간이 지나면서 가장 큰 보상을 얻기 위해 <span style=\"color:orange\"><b>정책 (Policy)</b></span>라 부르는 최상의 전략을 스스로 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8bde6e-39dd-4f51-8304-076ed60e0be5",
   "metadata": {},
   "source": [
    "## **1-3. 배치 학습과 온라인 학습**\n",
    "### 1-3.1. 배치 학습 (Batch Learning)  \n",
    "→ 가용한 데이터를 모두 사용해 훈련시켜야 한다.  \n",
    "→ 일반적으로 이 방식은 시간과 자원을 많이 소모하여 보통 오프라인에서 수행된다.  \n",
    "\n",
    "### 1-3.2. 온라인 학습 (Online Learning)  \n",
    "→ 데이터를 순차적으로 한 개씩 또는 <span style=\"color: orange\"><b>미니 배치(mini batch)</b></span>라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킴.  \n",
    "→ 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있다.  \n",
    "→ 컴퓨터 한 대의 메모리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템에도 온라인 학습 알고리즘을 사용할 수 있다. (외부 메모리 학습)  \n",
    "<span style=\"color: orange\"><b>< ! > 외부 메모리 학습은 보통 오프라인으로 실행되어 온라인 학습보다는 <span style=\"color: red\"><b>점진적 학습 (incremental learning)</b></span>이라 한다.</b></span>  \n",
    "    \n",
    "→ 변화하는 데이터에 얼마나 빠르게 적응하는지를 나타내는 파라미터를 <span style=\"color:orange\"><b>학습률 (learning rate)</b></span>라고 한다.  \n",
    "(1) 학습률을 높게하면 시스템이 데이터에 <span style=\"color:orange\"><b>빠르게 적응</b></span>하지만 예전 데이터를 <span style=\"color:orange\"><b>금방 잊는다.</b></span>  \n",
    "(2) 학습률이 낮으면 <span style=\"color:orange\"><b>더 느리게 학습되지만</b></span>, 새로운 데이터에 있는 잡음이나 대표성 없는 <span style=\"color:orange\"><b>데이터 포인트에 덜 민감해진다.</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07de1dc3-a79f-4cfe-bccc-3e3c50ea0ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio",
   "language": "python",
   "name": "bio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
