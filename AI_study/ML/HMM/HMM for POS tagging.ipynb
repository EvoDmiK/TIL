{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea36a00-cc91-4470-8aa8-4f60d3e70229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import *\n",
    "from hmmlearn import hmm\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13ab9a5-170a-4a13-ba49-256e346f4528",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP       = os.path.sep\n",
    "ROOT_PATH = SEP.join(os.getcwd().split(SEP)[:-2])\n",
    "DATA_PATH = f'{ROOT_PATH}/Dataset/NameEntity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833c6c7e-38f9-4732-ba2f-69929f25086b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'{DATA_PATH}/NERdataset.csv', encoding = 'latin1')\n",
    "df = df.fillna(method  = 'ffill')\n",
    "df = df.rename(columns = {'Sentence #' : 'sentence'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fbe4fff-011e-4fde-ab22-4a45b55c9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(text_column):\n",
    "    \n",
    "    text_column = text_column.str.lower()\n",
    "    text_column = text_column.str.replace(r'\\d+', 'NUM')\n",
    "    \n",
    "    stop_words  = set(stopwords.words('english'))\n",
    "    text_column = text_column.apply(lambda x: ' '.join([word for word in x.split() \n",
    "                                                        if word not in stop_words]))\n",
    "    return text_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9124f5-2688-4644-88a3-0c9e2a01b316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2465571/1970938494.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text_column = text_column.str.replace(r'\\d+', 'NUM')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        thousands\n",
       "1                 \n",
       "2    demonstrators\n",
       "3                 \n",
       "4          marched\n",
       "Name: Word, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = pre_processing(df.Word)\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cccef7ff-b296-4016-8239-2fede89f1caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence           Word  POS    Tag\n",
       "0  Sentence: 1      thousands  NNS      O\n",
       "2  Sentence: 1  demonstrators  NNS      O\n",
       "4  Sentence: 1        marched  VBN      O\n",
       "6  Sentence: 1         london  NNP  B-geo\n",
       "8  Sentence: 1        protest   VB      O"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = df\n",
    "df_['Word'] = preprocessed_df\n",
    "\n",
    "df_ = df_[(df_['Word'] !='') | (df_['Word'].isna())]\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f1d0f5-dd60-4f7e-ad76-b9f9918ca0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 29764, 29763)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags   = list(set(df.POS.values))\n",
    "words  = list(set(df.Word.values))\n",
    "words_ = list(set(df_.Word.values)) \n",
    "\n",
    "len(tags), len(words), len(words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cbcad54-c7dd-4724-bf6d-468c71abb278",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = df.drop('POS', axis = 1), df.POS\n",
    "gs   = GroupShuffleSplit(n_splits = 2, test_size = .33, random_state = 42)\n",
    "\n",
    "train_idx, test_idx = next(gs.split(x, y, groups = df['sentence']))\n",
    "train_data          = df.loc[train_idx]\n",
    "test_data           = df.loc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75c46eed-30e0-4f28-b142-b5a4b28cf6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_, y_ = df_.drop('POS', axis = 1), df_.POS\n",
    "df_.reset_index(drop = True, inplace = True)\n",
    "\n",
    "gs = GroupShuffleSplit(n_splits = 2, test_size = .33, random_state = 42)\n",
    "train_idx_, test_idx_ = next(gs.split(x_, y_, groups = df_['sentence']))\n",
    "train_data_           = df_.loc[train_idx_]\n",
    "test_data_            = df_.loc[test_idx_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb1c63e-bfd1-4d48-83cf-e027c4366316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 23607)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfupdate      = train_data.sample(frac = .15, replace = False, random_state = 42)\n",
    "dfupdate.Word = 'UNKNOWN'\n",
    "train_data.update(dfupdate)\n",
    "\n",
    "words   = list(set(train_data.Word.values))\n",
    "word2id = {w   : idx for idx, w in enumerate(words)}\n",
    "tag2id  = {t   : idx for idx, t in enumerate(tags)}\n",
    "id2tag  = {idx :   t for idx, t in enumerate(tags)}\n",
    "\n",
    "len(tags), len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de1f5be6-4a2b-4592-a032-4a51fc2b761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tags              = dict(train_data.POS.value_counts())\n",
    "count_tags_to_words     = train_data.groupby(['POS']).apply(lambda grp: grp.groupby('Word')['POS'].count().to_dict()).to_dict()\n",
    "count_init_tags         = dict(train_data.groupby('sentence').first().POS.value_counts())\n",
    "\n",
    "count_tags_to_next_tags = np.zeros((len(tags), len(tags)), dtype = int)\n",
    "sentences               = list(train_data.sentence)\n",
    "pos                     = list(train_data.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd5236c0-068c-4b9b-bfb1-3a5b6ac4e8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "702936it [00:00, 1070628.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in tqdm(enumerate(sentences), position = 0, leave = True):\n",
    "    \n",
    "    if (idx > 0) and (sentence == sentences[idx - 1]):\n",
    "        \n",
    "        prev_tagid = tag2id[pos[idx - 1]]\n",
    "        next_tagid = tag2id[pos[idx]]\n",
    "        \n",
    "        count_tags_to_next_tags[prev_tagid][next_tagid] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1205b345-d057-4af6-a2c2-d20a6047bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_prob            = np.zeros((len(tags), ))\n",
    "trans_mat             = np.zeros((len(tags), len(tags)))\n",
    "emission_prob         = np.zeros((len(tags), len(words)))\n",
    "num_sentences         = sum(count_init_tags.values())\n",
    "sum_tags_to_next_tags = np.sum(count_tags_to_next_tags, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b395c6e1-81f4-47f2-9d3b-afa32e4fd2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 87.97it/s]\n"
     ]
    }
   ],
   "source": [
    "for tag, tagid in tqdm(tag2id.items(), position = 0, leave = True):\n",
    "    \n",
    "    float_counttag    = float(count_tags.get(tag, 0))\n",
    "    start_prob[tagid] = count_init_tags.get(tag, 0) / num_sentences\n",
    "    \n",
    "    for word, wordid in word2id.items():\n",
    "        emission_prob[tagid][wordid] = count_tags_to_words.get(tag, {}).get(word, 0) / float_counttag\n",
    "        \n",
    "    \n",
    "    for tag_, tagid_ in tag2id.items():\n",
    "        trans_mat[tagid][tagid_] = count_tags_to_next_tags[tagid][tagid_] / sum_tags_to_next_tags[tagid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11fda485-3a8c-47b0-90a9-28f7c8ec312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words = {}\n",
    "for word in train_data.Word.values: count_words[word] = count_words.get(word, 0) + 1\n",
    "\n",
    "count_word_transitions = {}\n",
    "for sentence in train_data.groupby('sentence'):\n",
    "    \n",
    "    words = sentence[1]['Word'].values\n",
    "    for idx in range(len(words) - 1):\n",
    "        \n",
    "        w1, w2 = words[idx], words[idx + 1]\n",
    "        if w1 not in count_word_transitions:\n",
    "            count_word_transitions[w1] = {}\n",
    "            \n",
    "        count_word_transitions[w1][w2] = count_word_transitions[w1].get(w2, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8be127b-9f30-4930-bbce-00db2af26ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23607/23607 [05:06<00:00, 77.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23608, 23608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_transition_matrix  = np.zeros((len(word2id) + 1, len(word2id) + 1))\n",
    "sum_words_to_next_words = np.sum([\n",
    "                                    count_word_transitions[w1][w2] for w1 in count_word_transitions\n",
    "                                    for w2 in count_word_transitions[w1]\n",
    "                                ])\n",
    "for w1, w1id in tqdm(word2id.items()):\n",
    "    for w2, w2id in word2id.items():\n",
    "        word_transition_matrix[w1id][w2id] = count_word_transitions.get(w1, {}).get(w2, 0) / sum_words_to_next_words\n",
    "       \n",
    "print(word_transition_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc1aad6c-4728-4e32-80e2-9ae963f51408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_likelihood(sentence: List[str], word_transition_matrix) -> float:\n",
    "    \n",
    "    sentence_ids    = [word2id.get(w, word2id['UNKNOWN']) for w in sentence]\n",
    "    log_likelihood = np.log(word_transition_matrix[sentence_ids[0]][sentence_ids[1]])\n",
    "    \n",
    "    for idx in range(1, len(sentence_ids) - 1):\n",
    "        \n",
    "        log_likelihood += np.log(word_transition_matrix[sentence_ids[idx]][sentence_ids[idx + 1]] + 1e-10)\n",
    "        \n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdd1a1e6-1e83-4c48-b6ea-2a31d52cf3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-41.259970813020175"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_log_likelihood(['this', 'is', 'a', 'test', 'sentence'], word_transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d466b1a-be22-4a6c-922a-c131113166d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hmm.MultinomialHMM(n_components = len(tags), algorithm = 'viterbi',\n",
    "                           random_state = 42)\n",
    "\n",
    "model.startprob_    = start_prob\n",
    "model.transmat_     = trans_mat\n",
    "model.emissionprob_ = emission_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6a2d1f2-d469-4a2d-8b4f-60c057468e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "345639it [00:00, 2422453.78it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data.loc[~test_data['Word'].isin(words), 'Word'] = 'UNKNOWN'\n",
    "word_test = list(test_data.Word)\n",
    "samples   = []\n",
    "\n",
    "for idx, val in enumerate(word_test):\n",
    "    samples.append([word2id[val]])\n",
    "    \n",
    "lengths, count = [], 0\n",
    "sentences      = list(test_data.sentence)\n",
    "\n",
    "for idx, sentence in tqdm(enumerate(sentences), position = 0, leave = True):\n",
    "    \n",
    "    if (idx > 0) and (sentence == sentences[idx - 1]):\n",
    "        count += 1\n",
    "        \n",
    "    elif idx > 0:\n",
    "        lengths.append(count)\n",
    "        count = 1\n",
    "        \n",
    "    else: \n",
    "        count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "067e8a4c-e875-44ea-a93d-cb9e524e10fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 29,  6, ...,  7,  0, 27], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_predict = model.predict(samples, lengths)\n",
    "pos_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0c04429-36ec-4a12-857f-a8b79915faa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345615, 345639, 345639, 345639)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_test = list(test_data.POS)\n",
    "pos_test  = np.zeros((len(tags_test), ), dtype = int)\n",
    "\n",
    "for idx, val in enumerate(tags_test):\n",
    "    pos_test[idx] = tag2id[val]\n",
    "    \n",
    "len(pos_predict), len(pos_test), len(samples), len(word_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "feb9bf33-d263-4afa-950d-9584d87b1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  accuracy is 28.67%\n",
      "The precision is 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dove/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The    recall is 0.29\n",
      "The  F1 Score is 0.21\n"
     ]
    }
   ],
   "source": [
    "def report(pred, gt):\n",
    "    \n",
    "    print(f'The  accuracy is {accuracy_score(gt, pred) * 100:.2f}%')\n",
    "    print(f'The precision is {precision_score(gt, pred, average = \"weighted\"):.2f}')\n",
    "    print(f'The    recall is {recall_score(gt, pred, average = \"weighted\"):.2f}')\n",
    "    print(f'The  F1 Score is {f1_score(gt, pred, average = \"weighted\"):.2f}')\n",
    "    \n",
    "\n",
    "min_length = min(len(pos_predict), len(pos_test))\n",
    "report(pos_predict[:min_length], pos_test[:min_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62635c1e-7ee1-4541-8077-bbdbe14ab630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dove",
   "language": "python",
   "name": "dove"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
