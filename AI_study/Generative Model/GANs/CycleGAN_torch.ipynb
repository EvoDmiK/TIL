{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65531688-f821-470e-b598-05edd1a6fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from imutils.paths import list_images\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "from misc.model import Generator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed48092-d65c-4f56-9134-020f17a253be",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP        = os.path.sep\n",
    "ROOT_PATH  = SEP.join(os.getcwd().split(SEP)[:-3])\n",
    "DATA_PATH  = f'{ROOT_PATH}/Dataset/apple2orange'\n",
    "\n",
    "DEVICE     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS     = 100\n",
    "LR         = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ee7e66-f559-4a52-aebf-b6cb66193d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = image / 127.5 - 1\n",
    "    return (image)\n",
    "\n",
    "\n",
    "def build_dataset(path):\n",
    "    \n",
    "    images      = []\n",
    "    image_paths = list_images(path)\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = preprocess_image(image)\n",
    "        \n",
    "        images.append(image)\n",
    "        \n",
    "    return np.array(images, dtype = 'float32')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652e5f43-ca7d-4af0-b559-5e8fefa6f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A = build_dataset(f'{DATA_PATH}/trainA')\n",
    "train_B = build_dataset(f'{DATA_PATH}/trainB')\n",
    "\n",
    "test_A  = build_dataset(f'{DATA_PATH}/testA')\n",
    "test_B  = build_dataset(f'{DATA_PATH}/testB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7e8111-2642-4ef7-89ce-596ed02d9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppleOrangeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, images, dtype = 'train'):\n",
    "        \n",
    "        self.images = images\n",
    "        self.dtype  = dtype\n",
    "        \n",
    "        self.transforms          = {}\n",
    "        self.transforms['train'] = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize([286, 286]),\n",
    "                                        transforms.RandomCrop(256),\n",
    "                                        transforms.ToTensor()\n",
    "                                    ])\n",
    "        self.transforms['test']  = transforms.Compose([\n",
    "                                        transforms.ToPILImage(),\n",
    "                                        transforms.Resize([256, 256]),\n",
    "                                        transforms.ToTensor()\n",
    "                                    ])\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.images[idx]\n",
    "        image = self.transforms[self.dtype](image)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d020cf-6df1-405c-92ff-322922b7e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A = AppleOrangeDataset(train_A)\n",
    "train_B = AppleOrangeDataset(train_B)\n",
    "\n",
    "test_A  = AppleOrangeDataset(test_A, dtype = 'test')\n",
    "test_B  = AppleOrangeDataset(test_B, dtype = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47089a10-5423-4644-99ab-0a0d74e82f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_A = DataLoader(train_A, batch_size = BATCH_SIZE)\n",
    "train_loader_B = DataLoader(train_A, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af8e8f-cf03-4d9b-b5dd-f293965e90ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
