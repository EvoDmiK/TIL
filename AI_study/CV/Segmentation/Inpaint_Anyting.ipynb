{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ed1df5-cd7b-411d-87d5-4c1c8b070b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectron v2 is not installed\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from segment_anything import build_sam, SamAutomaticMaskGenerator\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "from easydict import EasyDict as edict\n",
    "from matplotlib import pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "from IA.lama_inpaint import inpaint_img_with_lama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466a8d50-61f7-4aeb-8420-f3df33608643",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH  = os.getcwd()\n",
    "DATA_PATH  = f'{ROOT_PATH}/data/dove.jpg'\n",
    "MODEL_PATH = f'{ROOT_PATH}/checkpoint/sam_vit_h.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72bab157-4fb4-40af-9537-ad809c19d3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torch/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "device        = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "image         = np.array(Image.open(DATA_PATH).convert('RGB'))\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3517f-fe2d-4114-a23e-058eea54c9f7",
   "metadata": {},
   "source": [
    "![원본 이미지](./data/dove.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "126ba4f8-ca0c-4957-a10c-6eec18467d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model        = build_sam(checkpoint = MODEL_PATH).to(device)\n",
    "generator    = SamAutomaticMaskGenerator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67e75a1c-c344-44d3-98d5-f6c742c6caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks        = generator.generate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36e9897-0235-4f6b-b53c-8fa73db91c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_cp     = image.copy()\n",
    "random_color = lambda : np.random.randint(0, 256)\n",
    "\n",
    "\n",
    "for idx, mask in enumerate(masks):\n",
    "    \n",
    "    x, y         = list(map(int, mask['point_coords'][0]))\n",
    "    seg          = mask['segmentation']\n",
    "    seg          = seg + np.zeros(seg.shape, np.uint8)\n",
    "    _, bin_image = cv2.threshold(seg, 0, 127, cv2.THRESH_BINARY)\n",
    "    \n",
    "    \n",
    "    color        = (random_color(), random_color(), random_color())\n",
    "    masked_image = np.where(seg[..., None], color, image_cp)\n",
    "    image_cp     = cv2.addWeighted(image_cp, 0.8, masked_image, 0.2, 0, dtype = cv2.CV_32F)\n",
    "    \n",
    "    conts, _     = cv2.findContours(bin_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    for cont in conts: cv2.drawContours(image_cp, [cont], -1, color, 2)\n",
    "    \n",
    "    cv2.putText(image_cp, f'[{idx}]. x : {x}, y : {y}', (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "plt.imshow(image_cp.astype(np.uint32))\n",
    "plt.axis(False)\n",
    "\n",
    "cv2.imwrite('output/dove/masked.png', image_cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49be3c5-a6c9-4e8e-8ef7-40591532a88f",
   "metadata": {},
   "source": [
    "![마스크 씌워진 이미지](./data/output/dove/masked.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4049de3a-5b48-4ccd-818f-12bfcc517478",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['input_image']  = DATA_PATH\n",
    "args['coords_type']  = 'key_in'\n",
    "args['point_coords'] = masks[19]['point_coords']\n",
    "args['point_label']  = [1]\n",
    "args['output_dir']   = f'{DATA_PATH}/output'\n",
    "args['lama_config']  = f'{ROOT_PATH}/IA/lama/configs/prediction/default.yaml'\n",
    "args['lama_ckpt']    = f'{ROOT_PATH}/checkpoint/'\n",
    "\n",
    "args = edict(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507132e7-daa2-49fb-b2c3-6529dfcbc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_coords = np.array(args.point_coords)\n",
    "point_label  = np.array(args.point_label)\n",
    "\n",
    "sam          = sam_model_registry['vit_h'](checkpoint = MODEL_PATH).to(device)\n",
    "predictor    = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73669851-b0fe-4b23-8f8e-03d8508ba751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[421.875  , 613.59375]]), array([1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_coords, point_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a253b102-e264-456a-8ef7-2749d4a3724c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords = torch.as_tensor(point_coords)\n",
    "coords.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50bd8543-9b4f-4cbc-aa1c-382f5b5d7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.set_image(image)\n",
    "masks_, _, _ = predictor.predict(\n",
    "                point_coords     = point_coords,\n",
    "                point_labels     = point_label,\n",
    "                multimask_output = False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea637bbf-ad8a-4746-bb24-eb44b09868cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_   = masks_.astype(np.uint8) * 255\n",
    "img_stem = Path(DATA_PATH).stem\n",
    "out_dir  = Path(args.output_dir) / img_stem\n",
    "out_dir.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26a8a927-87cb-4f93-a34a-74b7679826f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, mask in enumerate(masks_):\n",
    "    \n",
    "    mask_path         = out_dir / f'mask_{idx}.png'\n",
    "    image_points_path = out_dir / f'with_points.png'\n",
    "    image_mask_path   = out_dir / f'with_{Path(mask_path).name}'\n",
    "    \n",
    "    Image.fromarray(mask.astype(np.uint8)).save(mask_path)\n",
    "    dpi  = plt.rcParams['figure.dpi']\n",
    "    H, W = image.shape[:2] \n",
    "    \n",
    "    plt.figure(figsize = (W * 0.77 / dpi, H * 0.77 / dpi))\n",
    "    plt.imshow(image)\n",
    "    plt.axis(False)\n",
    "    \n",
    "    coords      = np.array(args.point_coords)\n",
    "    labels      = np.array(args.point_label)\n",
    "    color_table = {0 : 'red', 1 : 'green'}\n",
    "    \n",
    "    for label_value, color in color_table.items():\n",
    "        \n",
    "        points = coords[labels == label_value]\n",
    "        plt.gca().scatter(points[:, 0], points[:, 1], color = color,\n",
    "                          marker = '*', s = (W*0.04)**2, edgecolor = 'white',\n",
    "                         linewidth = 1.25)\n",
    "        \n",
    "    plt.savefig(image_points_path, bbox_inches = 'tight', pad_inches = 0)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    \n",
    "    if np.max(mask) == 255: mask = mask / 255\n",
    "    color = np.array([30 / 255, 144 / 255, 255 / 255, 0.6])\n",
    "    h, w  = mask.shape[-2:]\n",
    "    \n",
    "    mask_img = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    plt.gca().imshow(mask_img)\n",
    "    \n",
    "    plt.savefig(image_mask_path, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431e20db-010a-4640-b036-e30976bd723f",
   "metadata": {},
   "source": [
    "![마스크 이미지](./data/output/dove/mask_0.png)\n",
    "![마스크 씌워진 이미지](./data/output/dove/with_mask_0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ded5b476-af44-441a-add8-6159998879c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, mask in enumerate(masks_):\n",
    "        \n",
    "        mask_path        = out_dir / f'mask{idx}.png'\n",
    "        img_inpaint_path = out_dir / f'inp_with_{Path(mask_path).name}'\n",
    "        img_inpainted    = inpaint_img_with_lama(\n",
    "                                image, mask, args.lama_config,\n",
    "                                args.lama_ckpt, device = device\n",
    "                            )\n",
    "        \n",
    "        Image.fromarray(img_inpainted.astype(np.uint8)).save(img_inpaint_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b60383a-ba5a-4e39-99f3-f809ac9463be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f03b0284fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(img_inpainted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d6995-ea04-40b4-9c5a-3719e76fcce8",
   "metadata": {},
   "source": [
    "![lama 이미지](./data/output/dove/inp_with_mask0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83206416-d695-4b8f-b4d5-9f8ff884a436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
