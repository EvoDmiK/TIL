{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb7f785-e9f2-4cd4-a672-346d18f6f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from easydict import EasyDict as edict\n",
    "from tensorboardX import SummaryWriter\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dataset import dataset\n",
    "from dataset import sampler\n",
    "from net.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8540e29-6bc0-46cb-90ef-1c1fd6f60b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "args                    = edict({})\n",
    "args.lr                 = 1e-4\n",
    "args.device             = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args.epochs             = 160_000\n",
    "args.lr_decay           = 5e-5\n",
    "args.save_dir           = 'assets/results'\n",
    "args.n_threads          = 16\n",
    "args.batch_size         = 8 \n",
    "args.style_path         = 'assets/styles'\n",
    "args.style_weight       = 10.0\n",
    "\n",
    "## reference : https://drive.google.com/file/d/1EpkBA2K2eYILDSyPTt0fztz59UjAIpZU/view\n",
    "args.encoder_path       = 'assets/vgg_normalised.pth'\n",
    "args.contents_path      = 'assets/contents'\n",
    "args.content_weight     = 1.0\n",
    "args.save_ckpt_interval = 10_000\n",
    "\n",
    "os.makedirs(          args.save_dir, exist_ok = True)\n",
    "os.makedirs(f'{args.save_dir}/logs', exist_ok = True)\n",
    "writer = SummaryWriter(log_dir = f'{args.save_dir}/logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d66b11e7-c8b0-406d-a8c6-4f18af5a2df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 구성 완.\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder()\n",
    "encoder = Encoder()\n",
    "encoder.load_state_dict(torch.load(args.encoder_path), strict = False)\n",
    "\n",
    "encoder = nn.Sequential(*list(encoder.children())[:31])\n",
    "model   = Net(encoder, decoder).to(args.device)\n",
    "model.train()\n",
    "\n",
    "print('모델 구성 완.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0844c388-5f22-4083-ac66-3dbd4482695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_lr(optimizer, iter_cnt):\n",
    "\n",
    "    lr = args.lr / (1.0 + args.lr_decay * iter_cnt)\n",
    "    for param in optimizer.param_groups: param['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b869b47-abc9-4f2b-ac6f-61b7f2de97ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_tf = dataset.train_transform()\n",
    "style_tf   = dataset.train_transform()\n",
    "\n",
    "content_dataset = dataset.StyleTransferDataset(args.contents_path, content_tf)\n",
    "style_dataset   = dataset.StyleTransferDataset(   args.style_path,   style_tf)\n",
    "\n",
    "content_iter    = iter(DataLoader(content_dataset, batch_size = args.batch_size,\n",
    "                                  sampler = sampler.InfiniteSamplerWrapper(content_dataset),\n",
    "                                  num_workers = args.n_threads))\n",
    "\n",
    "style_iter      = iter(DataLoader(style_dataset, batch_size = args.batch_size,\n",
    "                                  sampler = sampler.InfiniteSamplerWrapper(style_dataset),\n",
    "                                  num_workers = args.n_threads))\n",
    "\n",
    "optimizer       = torch.optim.Adam(model.decoder.parameters(), lr = args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4a509cf-5803-460c-9d51-7d3cd4e7cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 10002/160000 [10:27<2:42:12, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.301\n",
      "        loss : 0.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 20002/160000 [20:52<2:31:58, 15.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.320\n",
      "        loss : 0.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 30002/160000 [31:18<2:19:45, 15.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.287\n",
      "        loss : 0.287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 40002/160000 [41:44<2:08:41, 15.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.272\n",
      "        loss : 0.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 50002/160000 [52:08<1:58:20, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.275\n",
      "        loss : 0.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 60002/160000 [1:02:35<1:47:28, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.320\n",
      "        loss : 0.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 70002/160000 [1:13:03<1:37:19, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.262\n",
      "        loss : 0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 80002/160000 [1:23:31<1:26:05, 15.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.286\n",
      "        loss : 0.286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 90002/160000 [1:33:57<1:15:13, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.319\n",
      "        loss : 0.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 100002/160000 [1:44:23<1:04:27, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.287\n",
      "        loss : 0.287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 110002/160000 [1:54:53<55:48, 14.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.290\n",
      "        loss : 0.290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 120002/160000 [2:05:21<42:59, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.326\n",
      "        loss : 0.326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 130002/160000 [2:15:49<32:21, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.297\n",
      "        loss : 0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 140002/160000 [2:26:17<21:54, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.287\n",
      "        loss : 0.287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 150002/160000 [2:36:45<10:46, 15.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.282\n",
      "        loss : 0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160000/160000 [2:47:14<00:00, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content loss : 0.000\n",
      "  style loss : 0.294\n",
      "        loss : 0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, args.epochs + 1)):\n",
    "\n",
    "    adjust_lr(optimizer, iter_cnt = epoch)\n",
    "    content_images = next(content_iter).to(args.device)\n",
    "    style_images   = next(style_iter).to(args.device)\n",
    "\n",
    "    loss_c, loss_s = model(content_images, style_images)\n",
    "    loss_c         = args.content_weight * loss_c\n",
    "    loss_s         =   args.style_weight * loss_s\n",
    "    loss           = loss_c + loss_s\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    writer.add_scalar('content loss', loss_c.item(), epoch)\n",
    "    writer.add_scalar(  'style loss', loss_s.item(), epoch)\n",
    "\n",
    "    if epoch % args.save_ckpt_interval == 0 or epoch == args.epochs:\n",
    "\n",
    "        print(f'content loss : {loss_c.item():.3f}')\n",
    "        print(f'  style loss : {loss_s.item():.3f}')\n",
    "        print(f'        loss : {loss.item():.3f}')\n",
    "        state_dict = model.decoder.state_dict()\n",
    "        for k in state_dict.keys(): state_dict[k] = state_dict[k].to(torch.device('cpu'))\n",
    "\n",
    "        torch.save(state_dict, f'{args.save_dir}/decoder_{str(epoch).zfill(6)}.pth')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e868d93-ed83-4240-b133-57a5e6c87b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1.x",
   "language": "python",
   "name": "torch_1.x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
