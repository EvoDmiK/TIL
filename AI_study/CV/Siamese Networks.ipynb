{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18430109-4ccb-4403-ae10-54bed69fa913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 02:12:17.144956: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "from imutils.paths import list_images\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import easydict\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aebaf709-4b26-4a11-ba1a-e06c0ddb8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = ''\n",
    "TEST_DATASET  = ''\n",
    "\n",
    "EPOCHS           = 10\n",
    "IMAGE_SIZE       = (224, 224)\n",
    "BATCH_SIZE       = 256\n",
    "BUFFER_SIZE      = BATCH_SIZE * 2\n",
    "LEARNING_RATE    = 1e-4\n",
    "STEPS_PER_EPOCH  = 50\n",
    "VALIDATION_STEPS = 10\n",
    "\n",
    "AUTO              = tf.data.AUTOTUNE\n",
    "MODEL_PATH        = os.path.join('output', 'siamese_network')\n",
    "OUTPUT_IMAGE_PATH = os.path.join('output', 'output_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0116e4d-852d-4bc0-8c4f-5342dd469401",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapFunction:\n",
    "    \n",
    "    def __init__(self, image_size):\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    \n",
    "    def decode_and_resize(self, image_path):\n",
    "        \n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels = 3)\n",
    "        \n",
    "        image = tf.image.convert_image_dtype(image, dtype = tf.float32)\n",
    "        image = tf.image.resize(image, self.image_size)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    \n",
    "    def __call__(self, achor, positive, negative):\n",
    "        \n",
    "        anchor   = self.decode_and_resize(anchor)\n",
    "        positive = self.decode_and_resize(positive)\n",
    "        negative = self.decode_and_resize(negative)\n",
    "        \n",
    "        return (anchor, positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "028353dc-5b84-40a5-9633-57ab019b0afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletGenerator:\n",
    "    \n",
    "    def __init__(self, dataset_path):\n",
    "        \n",
    "        self.people_names = list()\n",
    "        for folder_name in os.listdir(dataset_path):\n",
    "            \n",
    "            absolute_folder_name = os.path.join(dataset_path, folder_name)\n",
    "            num_images           = len(os.listdir(absolute_folder_name))\n",
    "            \n",
    "            if num_images > 1: self.people_names.append(absolute_folder_name)\n",
    "            \n",
    "        self.all_people = self.generate_all_people_dict()\n",
    "        \n",
    "        \n",
    "    def generate_all_people_dict(self):\n",
    "        \n",
    "        all_people = dict()\n",
    "        for person_name in self.people_names:\n",
    "            \n",
    "            image_names   = os.listdir(person_name)\n",
    "            person_photos = [ \n",
    "                os.path.join(person_name, image_name) for image_name in image_names\n",
    "            ]\n",
    "            all_people[person_name] = person_photos\n",
    "            \n",
    "        return all_people\n",
    "    \n",
    "    \n",
    "    def get_next_element(self):\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            anchor_name     = random.choice(self.people_names)\n",
    "            temporary_names = self.people_names.copy()\n",
    "            temporary_names.remove(anchor_name)\n",
    "            \n",
    "            negative_name = random.choice(temporary_names)\n",
    "            (anchor_photo, positive_photo) = np.random.choice(\n",
    "                a     = self.all_people[anchor_name],\n",
    "                size = 2, replace = False\n",
    "            )\n",
    "            \n",
    "            negative_photo = random.choice(self.all_people[negative_name])\n",
    "            yield (anchor_photo, positive_photo, negative_photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92c16f9-6813-4ef6-9055-38517f126e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe976db-84d9-40cc-84fd-3345d9bdf53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd9f94-f459-4d2f-a07c-34a92b101acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
