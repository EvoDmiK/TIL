{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4bdb87f-4924-49c6-ae74-a1809c7e8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from medmnist.dataset import BloodMNIST\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e5fa52-6d66-4b9d-b8b0-d411cb4331e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/dataset/blood_mnist'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_PATH = '/'.join(os.getcwd().split('/')[:-2])\n",
    "DATA_PATH = f'{ROOT_PATH}/dataset/blood_mnist'\n",
    "\n",
    "BATCH_SIZE = 64 \n",
    "INIT_LR    = 1e-3\n",
    "EPOCHS     = 10\n",
    "DEVICE     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DECAY      = 1e-5\n",
    "\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b4184e-dc9f-4c2d-8638-72d844cbba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {}\n",
    "transform['train'] = transforms.Compose([\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.Resize((28, 28)),\n",
    "                                    transforms.ToTensor()\n",
    "                                ])\n",
    "\n",
    "transform['valid'] = transforms.Compose([\n",
    "                                    transforms.Resize((28, 28)),\n",
    "                                    transforms.ToTensor()\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9696dc6-edb4-4e3d-96c5-676b33d71a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/dataset/blood_mnist/bloodmnist.npz\n",
      "Using downloaded and verified file: /home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/dataset/blood_mnist/bloodmnist.npz\n",
      "Using downloaded and verified file: /home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/dataset/blood_mnist/bloodmnist.npz\n"
     ]
    }
   ],
   "source": [
    "train_dataset = BloodMNIST(split  = 'train', download  = True,\n",
    "                           as_rgb = True   , transform = transform['train'],\n",
    "                           root   = DATA_PATH) \n",
    "\n",
    "valid_dataset = BloodMNIST(split  = 'val', download  = True,\n",
    "                           as_rgb =  True, transform = transform['valid'], \n",
    "                           root   = DATA_PATH)\n",
    "\n",
    "test_dataset  = BloodMNIST(split  = 'test', download  = True,\n",
    "                           as_rgb =   True, transform = transform['valid'],\n",
    "                           root   = DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a468b1-b098-4c35-a14c-64eb324b8ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle = True,  batch_size = BATCH_SIZE)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle = False, batch_size = BATCH_SIZE)\n",
    "test_loader  = DataLoader(test_dataset , shuffle = False, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e976238-d460-4376-812e-1927c6304905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloodNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        \n",
    "        super(BloodNet, self).__init__()\n",
    "        \n",
    "        self.conv1   = self.ConvBlock(3,  16, 3)\n",
    "        self.conv2   = self.ConvBlock(16, 16, 3)\n",
    "        self.conv3   = self.ConvBlock(16, 64, 3)\n",
    "        self.conv4   = self.ConvBlock(64, 64, 3)\n",
    "        self.conv5   = self.ConvBlock(64, 64, 3, 1)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.linear  = self.LinearBlock(64, n_classes)\n",
    "        \n",
    "        \n",
    "    def ConvBlock(self, in_feats, out_feats, kernel_size = None, padding = None):\n",
    "        \n",
    "        layers = nn.Sequential(\n",
    "                    nn.Conv2d(in_feats, out_feats, kernel_size = kernel_size, \n",
    "                              padding = padding),\n",
    "                    nn.BatchNorm2d(out_feats),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    \n",
    "    def LinearBlock(self, in_feats, n_classes):\n",
    "        \n",
    "        layers = nn.Sequential(\n",
    "                    nn.Linear(in_feats * 4 * 4, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, n_classes)\n",
    "                )\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        print(x.size(), '\\n\\n')\n",
    "        x = self.conv1(x)\n",
    "        x = self.pooling(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pooling(self.conv5(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aaefa7a-70c8-4b5a-9883-19c6e8c83826",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(set(train_dataset.labels.T.tolist()[0]))\n",
    "model     = BloodNet(n_classes).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params = model.parameters(), lr = INIT_LR, \n",
    "                       weight_decay = DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a156aaf-bbbf-48ae-b634-5af761a81341",
   "metadata": {},
   "outputs": [],
   "source": [
    "history          = {\n",
    "                        'train' : {\n",
    "                                    'loss' : [], 'accuracy' : [], 'f1' : []\n",
    "                                },\n",
    "    \n",
    "                        'valid' : {\n",
    "                                'loss' : [], 'accuracy' : [], 'f1' : []\n",
    "                            },\n",
    "                    }\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer):\n",
    "    \n",
    "    total_loss  = 0\n",
    "    correct     = 0\n",
    "    \n",
    "    gt, predict = [], []\n",
    "    model.train()\n",
    "    \n",
    "    for image, label in tqdm(train_loader):\n",
    "        \n",
    "        image       = image.float().to(DEVICE)\n",
    "        label       = label.to(DEVICE)\n",
    "        \n",
    "        outputs     = model(image)\n",
    "        _, preds    = torch.max(outputs, 1)\n",
    "        loss        = criterion(outputs, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        correct    += torch.sum(preds == label.data)\n",
    "        predicted  += preds.detach().numpy().tolist()\n",
    "        gt         += label.detach().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy =    correct / (len(train_loader) * BATCH_SIZE)\n",
    "    f1       = f1_score(gt,predicted)\n",
    "    \n",
    "    print(f'[TRAIN] loss : {avg_loss:.2f} | accuracy : {accuracy:.2f} | f1 : {f1}')\n",
    "    history['train']['loss'].append(avg_loss)\n",
    "    history['train']['accuracy'].append(accuracy)\n",
    "    history['train']['f1'].append(f1)\n",
    "    \n",
    "    \n",
    "def valid(model, valid_loader):\n",
    "    \n",
    "    total_loss, correct =  0, 0\n",
    "    gt, predicted       = [], []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for image, label in tqdm(valid_loader):\n",
    "            \n",
    "            image    = image.float().to(DEVICE)\n",
    "            label    = label.to(DEVICE)\n",
    "            \n",
    "            outputs  = model(image)\n",
    "            loss     = criterion(outputs, label)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            correct    += torch.sum(preds == label.data)\n",
    "            \n",
    "            predicted  += preds.detach().cpu().numpy().tolist()\n",
    "            gt         += label.detach().cpu().numpy().tolist()\n",
    "            \n",
    "    \n",
    "    avg_loss = total_loss / len(valid_loader)\n",
    "    accuracy = correct   / (len(valid_loader) * BATCH_SIZE)\n",
    "    f1       = f1_score(gt, predicted)\n",
    "    \n",
    "    print(f'[VALID] loss : {avg_loss} | accuracy : {accuracy} | f1 : {f1}')\n",
    "    history['valid']['loss'].append(avg_loss)\n",
    "    history['valid']['accuracy'].append(accuracy)\n",
    "    history['valid']['f1'].append(f1)\n",
    "    \n",
    "    return weigted_f1\n",
    "\n",
    "\n",
    "def run(model, train_loader, valid_loader):\n",
    "    \n",
    "    early_stopping_cnt = 0\n",
    "    best_f1            = -1\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        print(f'[{epoch + 1} / {EPOCHS}]')\n",
    "        train(model, train_loader, optimizer)\n",
    "        f1 = valid(model, valid_loader)\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            \n",
    "            os.makedirs('models/', exist_ok = True)\n",
    "            best_f1 = f1\n",
    "            early_stopping_cnt = 0\n",
    "            \n",
    "            torch.save(model, 'models/best_model.pt')\n",
    "            print(f'save model with f1 : {f1}')\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            early_stopping_cnt += 1\n",
    "            if early_stopping_counter >= 5:\n",
    "                print(f'Training Stopped by Early stopping counter : {early_stopping_counter}')\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de6b56e2-ce33-43b4-b6cd-1ab6ccf25555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/187 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 28, 28]) \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (Tensor, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 93\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(model, train_loader, valid_loader)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m valid(model, valid_loader)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f1 \u001b[38;5;241m>\u001b[39m best_f1:\n",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m image       \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     23\u001b[0m label       \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 25\u001b[0m outputs     \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m _, preds    \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m loss        \u001b[38;5;241m=\u001b[39m criterion(outputs, label)\n",
      "File \u001b[0;32m/opt/conda/envs/tensor/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[17], line 44\u001b[0m, in \u001b[0;36mBloodNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooling(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[1;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\n",
      "File \u001b[0;32m/opt/conda/envs/tensor/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/tensor/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/tensor/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/tensor/lib/python3.8/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tensor/lib/python3.8/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (Tensor, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (Tensor, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "run(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778dbac5-2645-4464-bc99-07fd1c1fdb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579c5805-3a04-4f5c-ad85-ed3120813c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3952c84-015c-46e3-9ea7-a33323116ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5013f91-775c-455f-bb45-ad845a2a4c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
