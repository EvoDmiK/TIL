{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce096507-5437-4a99-a55a-1c273a7452de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from medmnist.dataset import OrganAMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from ray.air import Checkpoint\n",
    "from sklearn.metrics import *\n",
    "import torch.optim as optim\n",
    "from ray.air import session\n",
    "from ray import air, tune\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "## 참고 : https://velog.io/@sdj4819/Focal-Loss\n",
    "from misc.FocalLoss import FocalLoss\n",
    "\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28845716-3fe7-4ace-994e-eafa6b44ede1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_PATH = '/'.join(os.getcwd().split('/')[:-2])\n",
    "DATA_PATH = f'{ROOT_PATH}/Dataset/organ_MNIST'\n",
    "DEVICE    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "os.makedirs(DATA_PATH, exist_ok = True)\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9322f818-3789-4686-9524-8f94fba0257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label = {\n",
    "                 0 : 'bladder',  1 :  'femur left', 2 :  'femur right',\n",
    "                 3 :   'heart',  4 : 'kidney left', 5 : 'kidney right',\n",
    "                 6 :   'liver',  7 :   'lung left', 8 :   'lung right',\n",
    "                 9 :'pancreas', 10 :      'spleen'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "546ba69d-1ece-4a76-815c-cb1331925c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrganNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        \n",
    "        super(OrganNet, self).__init__()\n",
    "        \n",
    "        self.conv1   = self.ConvBlock( 1, 16, 3)\n",
    "        self.conv2   = self.ConvBlock(16, 16, 3)\n",
    "        self.conv3   = self.ConvBlock(16, 64, 3)\n",
    "        self.conv4   = self.ConvBlock(64, 64, 3)\n",
    "        self.conv5   = self.ConvBlock(64, 64, 3, 1)\n",
    "        self.pooling = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.linear  = self.LinearBlock(64, n_classes)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def ConvBlock(self, in_feats, out_feats, kernel = 3, padding = None):\n",
    "            \n",
    "        Conv2d = nn.Conv2d(in_feats, out_feats, kernel_size = kernel) \\\n",
    "                 if padding == None else nn.Conv2d(in_feats, out_feats, kernel_size = kernel, padding = padding)\n",
    "        \n",
    "        layers = nn.Sequential(\n",
    "                    Conv2d,\n",
    "                    nn.BatchNorm2d(out_feats),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "    \n",
    "    def LinearBlock(self, in_feats, n_classes):\n",
    "        \n",
    "        layers = nn.Sequential(\n",
    "                    nn.Linear(in_feats * 4 * 4, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, n_classes)\n",
    "                )\n",
    "        \n",
    "        return layers\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.pooling(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.pooling(self.conv4(x))\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a0816e-52ea-455b-b98b-b946397f10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_counter = lambda dataset: sorted(Counter([lb[0] for lb in dataset.labels]).items())\n",
    "to_list    = lambda tensor: tensor.detach().cpu().numpy().tolist()\n",
    "\n",
    "def load_data():\n",
    "    transform           = {}\n",
    "    transform['train']  = transforms.Compose([\n",
    "                                    transforms.RandomVerticalFlip(),\n",
    "                                    transforms.Resize((28, 28)),\n",
    "                                    transforms.ToTensor()\n",
    "                            ]) \n",
    "    transform['valid']  = transforms.Compose([\n",
    "                                transforms.Resize((28, 28)),\n",
    "                                transforms.ToTensor()\n",
    "                            ])\n",
    "\n",
    "    train_dataset = OrganAMNIST(\n",
    "                                    split  = 'train', download  = True,\n",
    "                                    as_rgb = False  , transform = transform['train'],\n",
    "                                    root   = DATA_PATH\n",
    "                               )\n",
    "\n",
    "    valid_dataset = OrganAMNIST(\n",
    "                                    split  = 'val', download  = True,\n",
    "                                    as_rgb = False, transform = transform['valid'],\n",
    "                                    root   = DATA_PATH\n",
    "                              )\n",
    "    \n",
    "    return train_dataset, valid_dataset\n",
    "\n",
    "def train(model, loader, criterion, optimizer, batch_size):\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct    = 0\n",
    "    \n",
    "    gt, predicted  = [], []\n",
    "    \n",
    "    model.train()\n",
    "    for image, label in loader:\n",
    "        \n",
    "        image    = image.float().to(DEVICE)\n",
    "        label    = label.to(DEVICE).squeeze().long()\n",
    "        outputs  = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss     = criterion(outputs, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        correct    += torch.sum(preds == label.data)\n",
    "        predicted  += to_list(preds)\n",
    "        gt         += to_list(label)\n",
    "        \n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy =    correct / (len(loader) * batch_size)\n",
    "    accuracy = float(accuracy.detach().cpu().numpy())\n",
    "    f1       = f1_score(gt, predicted, average = 'weighted')\n",
    "    \n",
    "def valid(model, loader, criterion, batch_size):\n",
    "    \n",
    "    total_loss, correct =  0,  0\n",
    "    gt, predicted       = [], []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for image, label in loader:\n",
    "            \n",
    "            image    = image.float().to(DEVICE)\n",
    "            label    = label.to(DEVICE).squeeze().long()\n",
    "            outputs  = model(image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss     = criterion(outputs, label)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            correct    += torch.sum(preds == label.data)\n",
    "            \n",
    "            predicted  += to_list(preds)\n",
    "            gt         += to_list(label)\n",
    "            \n",
    "        \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = correct / (len(loader) * batch_size)\n",
    "    accuracy = float(accuracy.detach().cpu().numpy())\n",
    "    f1       = f1_score(gt, predicted, average = 'weighted')\n",
    "\n",
    "    return avg_loss, accuracy, f1\n",
    "\n",
    "\n",
    "def tune_function(config):\n",
    "    model     = OrganNet(n_classes = len(idx2label.keys())).to(DEVICE)\n",
    "        \n",
    "    criterion = config['criterion']\n",
    "    optimizer = config['optimizer'](model.parameters(), lr = config['lr'])\n",
    "        \n",
    "    to_list = lambda tensor: tensor.detach().cpu().numpy().tolist()\n",
    "    \n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle =  True, batch_size = config['batch_size'])\n",
    "    valid_loader = DataLoader(valid_dataset, shuffle = False, batch_size = config['batch_size'])\n",
    "    \n",
    "    train_count = [cnt[1] for cnt in lb_counter(train_dataset)]\n",
    "    alpha       = [1 - cnt / sum(train_count) for cnt in train_count]\n",
    "    \n",
    "    if 'focal' in criterion.__class__.__name__.lower():\n",
    "        criterion.alpha = alpha\n",
    "        criterion.gamma = config['gamma']\n",
    "\n",
    "    early_stopping_cnt =  0\n",
    "    \n",
    "    for epoch in range(config['epoch']):\n",
    "        train(model, train_loader, criterion, optimizer, config['batch_size'])\n",
    "        loss, accuracy, f1 = valid(model, valid_loader, criterion, config['batch_size'])\n",
    "        \n",
    "        os.makedirs('tuned_model', exist_ok = True)\n",
    "        checkpoint = Checkpoint.from_directory('tuned_model')\n",
    "        session.report({'loss' : loss, 'accuracy' : accuracy, 'f1' : f1}, checkpoint = checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eff5689-edef-4c25-a704-8b072938ba76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/AI_study/Dataset/organ_MNIST/organamnist.npz\n",
      "Using downloaded and verified file: /home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/AI_study/Dataset/organ_MNIST/organamnist.npz\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "            'criterion'  : tune.grid_search([FocalLoss(), nn.CrossEntropyLoss()]),\n",
    "            'lr'         : tune.loguniform(1e-7, 1e-2),\n",
    "            'batch_size' : tune.grid_search([8, 16, 32, 64, 128]),\n",
    "            'optimizer'  : tune.grid_search([optim.Adam, optim.SGD]),\n",
    "            'epoch'      : tune.grid_search([10, 15, 20]),\n",
    "            'gamma'      : tune.grid_search([0, 0.125, 0.25, 0.5, 1, 2, 5])\n",
    "        }\n",
    "\n",
    "train_dataset, valid_dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480287da-de37-429e-89fb-59d5cb3b74f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 08:53:15,709\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "2023-05-24 08:53:20,733\tINFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-05-24 08:54:24</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:03.34        </td></tr>\n",
       "<tr><td>Memory:      </td><td>62.8/1007.7 GiB    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=4<br>Bracket: Iter 16.000: None | Iter 8.000: None | Iter 4.000: 0.5868566632270813 | Iter 2.000: 0.4910714328289032 | Iter 1.000: 0.37931033968925476<br>Logical resource usage: 16.0/256 CPUs, 8.0/8 GPUs (0.0/1.0 accelerator_type:A100)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  ... 273 more trials not shown (273 PENDING)\n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status    </th><th>loc                   </th><th style=\"text-align: right;\">  batch_size</th><th>criterion         </th><th style=\"text-align: right;\">  epoch</th><th style=\"text-align: right;\">  gamma</th><th style=\"text-align: right;\">         lr</th><th>optimizer           </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">      f1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_function_6f3de_00000</td><td>RUNNING   </td><td>121.160.102.68:1592113</td><td style=\"text-align: right;\">           8</td><td>FocalLoss()       </td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">5.9822e-05 </td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        27.1615 </td><td style=\"text-align: right;\">0.445597</td><td style=\"text-align: right;\">  0.793411</td><td style=\"text-align: right;\">0.778323</td></tr>\n",
       "<tr><td>tune_function_6f3de_00001</td><td>RUNNING   </td><td>121.160.102.68:1592373</td><td style=\"text-align: right;\">          16</td><td>FocalLoss()       </td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">3.80643e-06</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        17.9292 </td><td style=\"text-align: right;\">1.47093 </td><td style=\"text-align: right;\">  0.37931 </td><td style=\"text-align: right;\">0.291246</td></tr>\n",
       "<tr><td>tune_function_6f3de_00004</td><td>RUNNING   </td><td>121.160.102.68:1592384</td><td style=\"text-align: right;\">         128</td><td>FocalLoss()       </td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">8.04893e-06</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        24.9931 </td><td style=\"text-align: right;\">1.06209 </td><td style=\"text-align: right;\">  0.586857</td><td style=\"text-align: right;\">0.561325</td></tr>\n",
       "<tr><td>tune_function_6f3de_00005</td><td>RUNNING   </td><td>121.160.102.68:1592446</td><td style=\"text-align: right;\">           8</td><td>CrossEntropyLoss()</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">7.40525e-05</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_function_6f3de_00006</td><td>RUNNING   </td><td>121.160.102.68:1592581</td><td style=\"text-align: right;\">          16</td><td>CrossEntropyLoss()</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">4.29617e-06</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        17.175  </td><td style=\"text-align: right;\">1.61422 </td><td style=\"text-align: right;\">  0.380234</td><td style=\"text-align: right;\">0.28758 </td></tr>\n",
       "<tr><td>tune_function_6f3de_00007</td><td>RUNNING   </td><td>121.160.102.68:1592774</td><td style=\"text-align: right;\">          32</td><td>CrossEntropyLoss()</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">0.000105145</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        20.4066 </td><td style=\"text-align: right;\">0.464368</td><td style=\"text-align: right;\">  0.80819 </td><td style=\"text-align: right;\">0.805074</td></tr>\n",
       "<tr><td>tune_function_6f3de_00010</td><td>RUNNING   </td><td>121.160.102.68:1592377</td><td style=\"text-align: right;\">           8</td><td>FocalLoss()       </td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">0.00197399 </td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_function_6f3de_00011</td><td>RUNNING   </td><td>121.160.102.68:1592381</td><td style=\"text-align: right;\">          16</td><td>FocalLoss()       </td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">2.81982e-06</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_function_6f3de_00012</td><td>PENDING   </td><td>                      </td><td style=\"text-align: right;\">          32</td><td>FocalLoss()       </td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">0.000287036</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_function_6f3de_00013</td><td>PENDING   </td><td>                      </td><td style=\"text-align: right;\">          64</td><td>FocalLoss()       </td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">0.000231454</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_function_6f3de_00014</td><td>PENDING   </td><td>                      </td><td style=\"text-align: right;\">         128</td><td>FocalLoss()       </td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">7.68549e-07</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_function_6f3de_00015</td><td>PENDING   </td><td>                      </td><td style=\"text-align: right;\">           8</td><td>CrossEntropyLoss()</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">3.29162e-06</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_function_6f3de_00016</td><td>PENDING   </td><td>                      </td><td style=\"text-align: right;\">          16</td><td>CrossEntropyLoss()</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">1.9711e-05 </td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_function_6f3de_00017</td><td>PENDING   </td><td>                      </td><td style=\"text-align: right;\">          32</td><td>CrossEntropyLoss()</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">6.78157e-06</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_function_6f3de_00018</td><td>PENDING   </td><td>                      </td><td style=\"text-align: right;\">          64</td><td>CrossEntropyLoss()</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">0.00401308 </td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_function_6f3de_00019</td><td>PENDING   </td><td>                      </td><td style=\"text-align: right;\">         128</td><td>CrossEntropyLoss()</td><td style=\"text-align: right;\">     15</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">7.39195e-05</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>tune_function_6f3de_00002</td><td>TERMINATED</td><td>121.160.102.68:1592377</td><td style=\"text-align: right;\">          32</td><td>FocalLoss()       </td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">4.22207e-06</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        21.3717 </td><td style=\"text-align: right;\">1.29432 </td><td style=\"text-align: right;\">  0.491071</td><td style=\"text-align: right;\">0.427025</td></tr>\n",
       "<tr><td>tune_function_6f3de_00003</td><td>TERMINATED</td><td>121.160.102.68:1592381</td><td style=\"text-align: right;\">          64</td><td>FocalLoss()       </td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">1.34168e-07</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.8358 </td><td style=\"text-align: right;\">2.12342 </td><td style=\"text-align: right;\">  0.135263</td><td style=\"text-align: right;\">0.127305</td></tr>\n",
       "<tr><td>tune_function_6f3de_00008</td><td>TERMINATED</td><td>121.160.102.68:1592381</td><td style=\"text-align: right;\">          64</td><td>CrossEntropyLoss()</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">5.23194e-07</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.65298</td><td style=\"text-align: right;\">2.36386 </td><td style=\"text-align: right;\">  0.13894 </td><td style=\"text-align: right;\">0.113302</td></tr>\n",
       "<tr><td>tune_function_6f3de_00009</td><td>TERMINATED</td><td>121.160.102.68:1592381</td><td style=\"text-align: right;\">         128</td><td>CrossEntropyLoss()</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">7.05309e-06</td><td>&lt;class &#x27;torch.o_06e0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.21597</td><td style=\"text-align: right;\">1.92799 </td><td style=\"text-align: right;\">  0.303615</td><td style=\"text-align: right;\">0.170501</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 08:53:21,238\tWARNING trial_runner.py:1575 -- The maximum number of pending trials has been automatically set to the number of available cluster CPUs, which is high (281 CPUs/pending trials). If you're running an experiment with a large number of trials, this could lead to scheduling overhead. In this case, consider setting the `TUNE_MAX_PENDING_TRIALS_PG` environment variable to the desired maximum number of concurrent trials.\n",
      "2023-05-24 08:53:53,591\tWARNING worker.py:1986 -- Warning: The actor ImplicitFunc is very large (30 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592113)\u001b[0m /home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/AI_study/CV/MIA/misc/FocalLoss.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592113)\u001b[0m   log_pt = F.log_softmax(input)\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592384)\u001b[0m /home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/AI_study/CV/MIA/misc/FocalLoss.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\u001b[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592384)\u001b[0m   log_pt = F.log_softmax(input)\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  accuracy</th><th>date               </th><th>done  </th><th style=\"text-align: right;\">      f1</th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">    loss</th><th>node_ip       </th><th style=\"text-align: right;\">    pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>tune_function_6f3de_00000</td><td style=\"text-align: right;\">  0.793411</td><td>2023-05-24_08-54-23</td><td>False </td><td style=\"text-align: right;\">0.778323</td><td>ubuntu    </td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">0.445597</td><td>121.160.102.68</td><td style=\"text-align: right;\">1592113</td><td>True               </td><td style=\"text-align: right;\">            27.1615 </td><td style=\"text-align: right;\">          27.1615 </td><td style=\"text-align: right;\">      27.1615 </td><td style=\"text-align: right;\"> 1684918463</td><td style=\"text-align: right;\">                   1</td><td>6f3de_00000</td></tr>\n",
       "<tr><td>tune_function_6f3de_00001</td><td style=\"text-align: right;\">  0.37931 </td><td>2023-05-24_08-54-16</td><td>False </td><td style=\"text-align: right;\">0.291246</td><td>ubuntu    </td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">1.47093 </td><td>121.160.102.68</td><td style=\"text-align: right;\">1592373</td><td>True               </td><td style=\"text-align: right;\">            17.9292 </td><td style=\"text-align: right;\">          17.9292 </td><td style=\"text-align: right;\">      17.9292 </td><td style=\"text-align: right;\"> 1684918456</td><td style=\"text-align: right;\">                   1</td><td>6f3de_00001</td></tr>\n",
       "<tr><td>tune_function_6f3de_00002</td><td style=\"text-align: right;\">  0.491071</td><td>2023-05-24_08-54-20</td><td>True  </td><td style=\"text-align: right;\">0.427025</td><td>ubuntu    </td><td style=\"text-align: right;\">                         2</td><td style=\"text-align: right;\">1.29432 </td><td>121.160.102.68</td><td style=\"text-align: right;\">1592377</td><td>True               </td><td style=\"text-align: right;\">            21.3717 </td><td style=\"text-align: right;\">           9.25627</td><td style=\"text-align: right;\">      21.3717 </td><td style=\"text-align: right;\"> 1684918460</td><td style=\"text-align: right;\">                   2</td><td>6f3de_00002</td></tr>\n",
       "<tr><td>tune_function_6f3de_00003</td><td style=\"text-align: right;\">  0.135263</td><td>2023-05-24_08-54-09</td><td>True  </td><td style=\"text-align: right;\">0.127305</td><td>ubuntu    </td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">2.12342 </td><td>121.160.102.68</td><td style=\"text-align: right;\">1592381</td><td>True               </td><td style=\"text-align: right;\">             9.8358 </td><td style=\"text-align: right;\">           9.8358 </td><td style=\"text-align: right;\">       9.8358 </td><td style=\"text-align: right;\"> 1684918449</td><td style=\"text-align: right;\">                   1</td><td>6f3de_00003</td></tr>\n",
       "<tr><td>tune_function_6f3de_00004</td><td style=\"text-align: right;\">  0.586857</td><td>2023-05-24_08-54-24</td><td>False </td><td style=\"text-align: right;\">0.561325</td><td>ubuntu    </td><td style=\"text-align: right;\">                         4</td><td style=\"text-align: right;\">1.06209 </td><td>121.160.102.68</td><td style=\"text-align: right;\">1592384</td><td>True               </td><td style=\"text-align: right;\">            24.9931 </td><td style=\"text-align: right;\">           5.24376</td><td style=\"text-align: right;\">      24.9931 </td><td style=\"text-align: right;\"> 1684918464</td><td style=\"text-align: right;\">                   4</td><td>6f3de_00004</td></tr>\n",
       "<tr><td>tune_function_6f3de_00005</td><td style=\"text-align: right;\">  0.809729</td><td>2023-05-24_08-54-26</td><td>False </td><td style=\"text-align: right;\">0.794907</td><td>ubuntu    </td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">0.472503</td><td>121.160.102.68</td><td style=\"text-align: right;\">1592446</td><td>True               </td><td style=\"text-align: right;\">            27.1213 </td><td style=\"text-align: right;\">          27.1213 </td><td style=\"text-align: right;\">      27.1213 </td><td style=\"text-align: right;\"> 1684918466</td><td style=\"text-align: right;\">                   1</td><td>6f3de_00005</td></tr>\n",
       "<tr><td>tune_function_6f3de_00006</td><td style=\"text-align: right;\">  0.380234</td><td>2023-05-24_08-54-17</td><td>False </td><td style=\"text-align: right;\">0.28758 </td><td>ubuntu    </td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">1.61422 </td><td>121.160.102.68</td><td style=\"text-align: right;\">1592581</td><td>True               </td><td style=\"text-align: right;\">            17.175  </td><td style=\"text-align: right;\">          17.175  </td><td style=\"text-align: right;\">      17.175  </td><td style=\"text-align: right;\"> 1684918457</td><td style=\"text-align: right;\">                   1</td><td>6f3de_00006</td></tr>\n",
       "<tr><td>tune_function_6f3de_00007</td><td style=\"text-align: right;\">  0.821121</td><td>2023-05-24_08-54-29</td><td>False </td><td style=\"text-align: right;\">0.808481</td><td>ubuntu    </td><td style=\"text-align: right;\">                         3</td><td style=\"text-align: right;\">0.427611</td><td>121.160.102.68</td><td style=\"text-align: right;\">1592774</td><td>True               </td><td style=\"text-align: right;\">            28.9541 </td><td style=\"text-align: right;\">           8.54751</td><td style=\"text-align: right;\">      28.9541 </td><td style=\"text-align: right;\"> 1684918469</td><td style=\"text-align: right;\">                   3</td><td>6f3de_00007</td></tr>\n",
       "<tr><td>tune_function_6f3de_00008</td><td style=\"text-align: right;\">  0.13894 </td><td>2023-05-24_08-54-15</td><td>True  </td><td style=\"text-align: right;\">0.113302</td><td>ubuntu    </td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">2.36386 </td><td>121.160.102.68</td><td style=\"text-align: right;\">1592381</td><td>True               </td><td style=\"text-align: right;\">             6.65298</td><td style=\"text-align: right;\">           6.65298</td><td style=\"text-align: right;\">       6.65298</td><td style=\"text-align: right;\"> 1684918455</td><td style=\"text-align: right;\">                   1</td><td>6f3de_00008</td></tr>\n",
       "<tr><td>tune_function_6f3de_00009</td><td style=\"text-align: right;\">  0.303615</td><td>2023-05-24_08-54-21</td><td>True  </td><td style=\"text-align: right;\">0.170501</td><td>ubuntu    </td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">1.92799 </td><td>121.160.102.68</td><td style=\"text-align: right;\">1592381</td><td>True               </td><td style=\"text-align: right;\">             5.21597</td><td style=\"text-align: right;\">           5.21597</td><td style=\"text-align: right;\">       5.21597</td><td style=\"text-align: right;\"> 1684918461</td><td style=\"text-align: right;\">                   1</td><td>6f3de_00009</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 08:54:09,272\tINFO tensorboardx.py:269 -- Removed the following hyperparameter values when logging to tensorboard: {'criterion': ('__ref_ph', 'f6251774'), 'optimizer': ('__ref_ph', '7bdb82fb')}\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592384)\u001b[0m /home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/AI_study/CV/MIA/misc/FocalLoss.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592384)\u001b[0m   log_pt = F.log_softmax(input)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "2023-05-24 08:54:15,950\tINFO tensorboardx.py:269 -- Removed the following hyperparameter values when logging to tensorboard: {'criterion': ('__ref_ph', '449a4ea2'), 'optimizer': ('__ref_ph', '7bdb82fb')}\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592384)\u001b[0m /home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/AI_study/CV/MIA/misc/FocalLoss.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592384)\u001b[0m   log_pt = F.log_softmax(input)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "2023-05-24 08:54:20,529\tINFO tensorboardx.py:269 -- Removed the following hyperparameter values when logging to tensorboard: {'criterion': ('__ref_ph', 'f6251774'), 'optimizer': ('__ref_ph', '7bdb82fb')}\n",
      "2023-05-24 08:54:21,187\tINFO tensorboardx.py:269 -- Removed the following hyperparameter values when logging to tensorboard: {'criterion': ('__ref_ph', '449a4ea2'), 'optimizer': ('__ref_ph', '7bdb82fb')}\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592384)\u001b[0m /home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/AI_study/CV/MIA/misc/FocalLoss.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592384)\u001b[0m   log_pt = F.log_softmax(input)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592384)\u001b[0m /home/jovyan/NVIDIA_CUDA-11.1_Samples/TIL/AI_study/CV/MIA/misc/FocalLoss.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(tune_function pid=1592384)\u001b[0m   log_pt = F.log_softmax(input)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "                max_t = 20, grace_period = 1, reduction_factor = 2\n",
    "            )\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "                tune.with_resources(\n",
    "                    tune.with_parameters(tune_function),\n",
    "                    resources = {'cpu' : 2, 'gpu' : 1}\n",
    "                ),\n",
    "                tune_config = tune.TuneConfig(\n",
    "                                metric = 'accuracy',\n",
    "                                mode   = 'max',\n",
    "                                scheduler = scheduler\n",
    "                            ),\n",
    "                param_space = config,\n",
    "            )\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7024d52e-89f7-449d-8fdd-b25af42ffdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResultGrid<[\n",
       "  Result(\n",
       "    metrics={'loss': 2.0876925903208114, 'accuracy': 0.09375, 'f1': 0.05604647312191422, 'should_checkpoint': True, 'done': True, 'trial_id': '53c40_00000', 'experiment_tag': '0_batch_size=64,criterion=ref_ph_f6251774,epoch=10,gamma=0.2500,lr=0.0000,optimizer=ref_ph_46a9caad'},\n",
       "    path='/home/jovyan/ray_results/tune_function_2023-05-24_08-38-09/tune_function_53c40_00000_0_batch_size=64,criterion=ref_ph_f6251774,epoch=10,gamma=0.2500,lr=0.0000,optimizer=ref_ph_46a9caad_2023-05-24_08-38-16',\n",
       "    checkpoint=Checkpoint(local_path=/home/jovyan/ray_results/tune_function_2023-05-24_08-38-09/tune_function_53c40_00000_0_batch_size=64,criterion=ref_ph_f6251774,epoch=10,gamma=0.2500,lr=0.0000,optimizer=ref_ph_46a9caad_2023-05-24_08-38-16/checkpoint_000009)\n",
       "  )\n",
       "]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc44a2-4c04-4239-bd7a-0bc8b6a9e147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
