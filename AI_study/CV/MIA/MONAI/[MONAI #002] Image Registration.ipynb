{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c35d75-b863-4cde-812b-e53235d243b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/envs/ml/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.2.0\n",
      "Numpy version: 1.25.2\n",
      "Pytorch version: 1.13.1.post200\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: c33f1ba588ee00229a309000e888f9817b4f1934\n",
      "MONAI __file__: /opt/conda/envs/ml/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.12\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: 0.21.0\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.14.1\n",
      "tqdm version: 4.66.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.5\n",
      "pandas version: 2.0.3\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: 4.32.0\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from monai.data   import DataLoader, Dataset, CacheDataset\n",
    "from monai.config import print_config, USE_COMPILED\n",
    "from monai.utils import set_determinism, first\n",
    "from monai.networks.nets import GlobalNet\n",
    "from monai.networks.blocks import Warp\n",
    "from monai.apps import MedNISTDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import MSELoss\n",
    "from monai import transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print_config()\n",
    "set_determinism(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe035a4-f1cc-453b-af82-b4b1b52d0a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP       = os.path.sep\n",
    "ROOT_PATH = SEP.join(os.getcwd().split(SEP)[:-4])\n",
    "DATA_PATH = f'{ROOT_PATH}/Datasets/MedNIST'\n",
    "\n",
    "os.makedirs(DATA_PATH, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17356a1-23ef-4e85-a704-0d135d34bf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-28 02:40:03,833 - INFO - Verified 'MedNIST.tar.gz', md5: 0bc7306e7427e00ad1c5526a6677552d.\n",
      "2023-08-28 02:40:03,834 - INFO - File exists: /home/jovyan/dove/utils/TIL/Datasets/MedNIST/MedNIST.tar.gz, skipped downloading.\n",
      "2023-08-28 02:40:03,835 - INFO - Non-empty folder exists in /home/jovyan/dove/utils/TIL/Datasets/MedNIST/MedNIST, skipped extracting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 47164/47164 [00:00<00:00, 147409.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample datas \n",
      "[{'fixed_hand': '/home/jovyan/dove/utils/TIL/Datasets/MedNIST/MedNIST/Hand/005758.jpeg', 'moving_hand': '/home/jovyan/dove/utils/TIL/Datasets/MedNIST/MedNIST/Hand/005758.jpeg'}, {'fixed_hand': '/home/jovyan/dove/utils/TIL/Datasets/MedNIST/MedNIST/Hand/007758.jpeg', 'moving_hand': '/home/jovyan/dove/utils/TIL/Datasets/MedNIST/MedNIST/Hand/007758.jpeg'}, {'fixed_hand': '/home/jovyan/dove/utils/TIL/Datasets/MedNIST/MedNIST/Hand/001798.jpeg', 'moving_hand': '/home/jovyan/dove/utils/TIL/Datasets/MedNIST/MedNIST/Hand/001798.jpeg'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data     = MedNISTDataset(DATA_PATH, section = 'training', \n",
    "                                download = True, transform=None)\n",
    "\n",
    "## 손 x-ray 데이터 셋을 이용한 image registration\n",
    "train_datadict = [{'fixed_hand' : item['image'], 'moving_hand' : item['image']}\n",
    "                  for item in train_data.data if item['label'] == 4]\n",
    "\n",
    "print(f'sample datas \\n{train_datadict[:3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96708c44-a83d-42ba-8417-519e8def5aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ml/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.io.dictionary LoadImaged.__init__:image_only: Current default value of argument `image_only=False` has been deprecated since version 1.1. It will be changed to `image_only=True` in version 1.3.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImageD(keys=[\"fixed_hand\", \"moving_hand\"]),\n",
    "        transforms.EnsureChannelFirstD(keys=[\"fixed_hand\", \"moving_hand\"]),\n",
    "        transforms.ScaleIntensityRanged(\n",
    "            keys=[\"fixed_hand\", \"moving_hand\"],\n",
    "            a_min=0.0,\n",
    "            a_max=255.0,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        transforms.RandRotateD(keys=[\"moving_hand\"], range_x=np.pi / 4, prob=1.0, keep_size=True, mode=\"bicubic\"),\n",
    "        transforms.RandZoomD(keys=[\"moving_hand\"], min_zoom=0.9, max_zoom=1.1, prob=1.0, mode=\"bicubic\", align_corners=False),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b35e59e-59e0-42e2-a118-9b551548af06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving image shape : torch.Size([64, 64])\n",
      "fixed  image shape : torch.Size([64, 64])\n"
     ]
    }
   ],
   "source": [
    "check_ds     = Dataset(data = train_datadict, transform = train_transforms)\n",
    "check_loader = DataLoader(check_ds, batch_size = 1, shuffle = True)\n",
    "check_data   = first(check_loader)\n",
    "fixed_image  = check_data['fixed_hand'][0][0]\n",
    "moving_image = check_data['moving_hand'][0][0]\n",
    "\n",
    "print(f'moving image shape : {moving_image.shape}')\n",
    "print(f'fixed  image shape : {fixed_image.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "702cc8b4-59ba-4a06-93ec-e9c5443a6f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 1000/1000 [00:01<00:00, 886.93it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds     = CacheDataset(data = train_datadict[:1000], transform = train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size = 16, shuffle = True, num_workers = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c96ae1-bc51-40a7-b648-33821152696c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ml/lib/python3.10/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/opt/conda/envs/ml/lib/python3.10/site-packages/monai/networks/blocks/warp.py:67: UserWarning: monai.networks.blocks.Warp: Using PyTorch native grid_sample.\n",
      "  warnings.warn(\"monai.networks.blocks.Warp: Using PyTorch native grid_sample.\")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model  = GlobalNet(image_size = (64, 64), spatial_dims = 2, in_channels = 2,\n",
    "                   num_channel_initial = 16, depth=3).to(device)\n",
    "\n",
    "image_loss = MSELoss()\n",
    "if USE_COMPILED: warp_layer = Warp(3, 'border').to(device)\n",
    "else: warp_layer = Warp('bilinear', 'border').to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c0862c-8b76-47d6-8ac3-782ee71828a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 200]\n",
      "epoch 1 avg loss : 0.052\n",
      "[2 / 200]\n",
      "epoch 2 avg loss : 0.047\n",
      "[3 / 200]\n",
      "epoch 3 avg loss : 0.046\n",
      "[4 / 200]\n",
      "epoch 4 avg loss : 0.044\n",
      "[5 / 200]\n",
      "epoch 5 avg loss : 0.042\n",
      "[6 / 200]\n",
      "epoch 6 avg loss : 0.040\n",
      "[7 / 200]\n",
      "epoch 7 avg loss : 0.040\n",
      "[8 / 200]\n",
      "epoch 8 avg loss : 0.037\n",
      "[9 / 200]\n",
      "epoch 9 avg loss : 0.036\n",
      "[10 / 200]\n",
      "epoch 10 avg loss : 0.036\n",
      "[11 / 200]\n",
      "epoch 11 avg loss : 0.034\n",
      "[12 / 200]\n",
      "epoch 12 avg loss : 0.033\n",
      "[13 / 200]\n",
      "epoch 13 avg loss : 0.033\n",
      "[14 / 200]\n",
      "epoch 14 avg loss : 0.031\n",
      "[15 / 200]\n",
      "epoch 15 avg loss : 0.029\n",
      "[16 / 200]\n",
      "epoch 16 avg loss : 0.029\n",
      "[17 / 200]\n",
      "epoch 17 avg loss : 0.028\n",
      "[18 / 200]\n",
      "epoch 18 avg loss : 0.027\n",
      "[19 / 200]\n",
      "epoch 19 avg loss : 0.027\n",
      "[20 / 200]\n",
      "epoch 20 avg loss : 0.025\n",
      "[21 / 200]\n",
      "epoch 21 avg loss : 0.026\n",
      "[22 / 200]\n",
      "epoch 22 avg loss : 0.026\n",
      "[23 / 200]\n",
      "epoch 23 avg loss : 0.024\n",
      "[24 / 200]\n",
      "epoch 24 avg loss : 0.024\n",
      "[25 / 200]\n",
      "epoch 25 avg loss : 0.023\n",
      "[26 / 200]\n",
      "epoch 26 avg loss : 0.023\n",
      "[27 / 200]\n",
      "epoch 27 avg loss : 0.022\n",
      "[28 / 200]\n",
      "epoch 28 avg loss : 0.022\n",
      "[29 / 200]\n",
      "epoch 29 avg loss : 0.021\n",
      "[30 / 200]\n",
      "epoch 30 avg loss : 0.020\n",
      "[31 / 200]\n",
      "epoch 31 avg loss : 0.019\n",
      "[32 / 200]\n",
      "epoch 32 avg loss : 0.019\n",
      "[33 / 200]\n",
      "epoch 33 avg loss : 0.020\n",
      "[34 / 200]\n",
      "epoch 34 avg loss : 0.019\n",
      "[35 / 200]\n",
      "epoch 35 avg loss : 0.023\n",
      "[36 / 200]\n",
      "epoch 36 avg loss : 0.019\n",
      "[37 / 200]\n",
      "epoch 37 avg loss : 0.020\n",
      "[38 / 200]\n",
      "epoch 38 avg loss : 0.018\n",
      "[39 / 200]\n",
      "epoch 39 avg loss : 0.018\n",
      "[40 / 200]\n",
      "epoch 40 avg loss : 0.018\n",
      "[41 / 200]\n",
      "epoch 41 avg loss : 0.017\n",
      "[42 / 200]\n",
      "epoch 42 avg loss : 0.017\n",
      "[43 / 200]\n",
      "epoch 43 avg loss : 0.018\n",
      "[44 / 200]\n",
      "epoch 44 avg loss : 0.018\n",
      "[45 / 200]\n",
      "epoch 45 avg loss : 0.019\n",
      "[46 / 200]\n",
      "epoch 46 avg loss : 0.017\n",
      "[47 / 200]\n",
      "epoch 47 avg loss : 0.017\n",
      "[48 / 200]\n",
      "epoch 48 avg loss : 0.017\n",
      "[49 / 200]\n",
      "epoch 49 avg loss : 0.018\n",
      "[50 / 200]\n",
      "epoch 50 avg loss : 0.017\n",
      "[51 / 200]\n",
      "epoch 51 avg loss : 0.016\n",
      "[52 / 200]\n",
      "epoch 52 avg loss : 0.015\n",
      "[53 / 200]\n",
      "epoch 53 avg loss : 0.015\n",
      "[54 / 200]\n",
      "epoch 54 avg loss : 0.016\n",
      "[55 / 200]\n",
      "epoch 55 avg loss : 0.016\n",
      "[56 / 200]\n",
      "epoch 56 avg loss : 0.015\n",
      "[57 / 200]\n",
      "epoch 57 avg loss : 0.016\n",
      "[58 / 200]\n",
      "epoch 58 avg loss : 0.014\n",
      "[59 / 200]\n",
      "epoch 59 avg loss : 0.016\n",
      "[60 / 200]\n",
      "epoch 60 avg loss : 0.015\n",
      "[61 / 200]\n",
      "epoch 61 avg loss : 0.016\n",
      "[62 / 200]\n",
      "epoch 62 avg loss : 0.015\n",
      "[63 / 200]\n",
      "epoch 63 avg loss : 0.015\n",
      "[64 / 200]\n",
      "epoch 64 avg loss : 0.014\n",
      "[65 / 200]\n",
      "epoch 65 avg loss : 0.015\n",
      "[66 / 200]\n",
      "epoch 66 avg loss : 0.014\n",
      "[67 / 200]\n",
      "epoch 67 avg loss : 0.015\n",
      "[68 / 200]\n",
      "epoch 68 avg loss : 0.016\n",
      "[69 / 200]\n",
      "epoch 69 avg loss : 0.016\n",
      "[70 / 200]\n",
      "epoch 70 avg loss : 0.014\n",
      "[71 / 200]\n",
      "epoch 71 avg loss : 0.013\n",
      "[72 / 200]\n",
      "epoch 72 avg loss : 0.014\n",
      "[73 / 200]\n",
      "epoch 73 avg loss : 0.014\n",
      "[74 / 200]\n",
      "epoch 74 avg loss : 0.014\n",
      "[75 / 200]\n",
      "epoch 75 avg loss : 0.014\n",
      "[76 / 200]\n",
      "epoch 76 avg loss : 0.013\n",
      "[77 / 200]\n",
      "epoch 77 avg loss : 0.014\n",
      "[78 / 200]\n",
      "epoch 78 avg loss : 0.014\n",
      "[79 / 200]\n",
      "epoch 79 avg loss : 0.015\n",
      "[80 / 200]\n",
      "epoch 80 avg loss : 0.013\n",
      "[81 / 200]\n",
      "epoch 81 avg loss : 0.013\n",
      "[82 / 200]\n",
      "epoch 82 avg loss : 0.014\n",
      "[83 / 200]\n",
      "epoch 83 avg loss : 0.014\n",
      "[84 / 200]\n",
      "epoch 84 avg loss : 0.013\n",
      "[85 / 200]\n",
      "epoch 85 avg loss : 0.015\n",
      "[86 / 200]\n",
      "epoch 86 avg loss : 0.014\n",
      "[87 / 200]\n",
      "epoch 87 avg loss : 0.015\n",
      "[88 / 200]\n",
      "epoch 88 avg loss : 0.014\n",
      "[89 / 200]\n",
      "epoch 89 avg loss : 0.013\n",
      "[90 / 200]\n",
      "epoch 90 avg loss : 0.015\n",
      "[91 / 200]\n",
      "epoch 91 avg loss : 0.013\n",
      "[92 / 200]\n",
      "epoch 92 avg loss : 0.013\n",
      "[93 / 200]\n",
      "epoch 93 avg loss : 0.014\n",
      "[94 / 200]\n",
      "epoch 94 avg loss : 0.014\n",
      "[95 / 200]\n",
      "epoch 95 avg loss : 0.013\n",
      "[96 / 200]\n",
      "epoch 96 avg loss : 0.012\n",
      "[97 / 200]\n",
      "epoch 97 avg loss : 0.014\n",
      "[98 / 200]\n",
      "epoch 98 avg loss : 0.013\n",
      "[99 / 200]\n",
      "epoch 99 avg loss : 0.013\n",
      "[100 / 200]\n",
      "epoch 100 avg loss : 0.012\n",
      "[101 / 200]\n",
      "epoch 101 avg loss : 0.014\n",
      "[102 / 200]\n",
      "epoch 102 avg loss : 0.013\n",
      "[103 / 200]\n",
      "epoch 103 avg loss : 0.012\n",
      "[104 / 200]\n",
      "epoch 104 avg loss : 0.012\n",
      "[105 / 200]\n",
      "epoch 105 avg loss : 0.012\n",
      "[106 / 200]\n",
      "epoch 106 avg loss : 0.012\n",
      "[107 / 200]\n",
      "epoch 107 avg loss : 0.013\n",
      "[108 / 200]\n",
      "epoch 108 avg loss : 0.012\n",
      "[109 / 200]\n",
      "epoch 109 avg loss : 0.012\n",
      "[110 / 200]\n",
      "epoch 110 avg loss : 0.012\n",
      "[111 / 200]\n",
      "epoch 111 avg loss : 0.014\n",
      "[112 / 200]\n",
      "epoch 112 avg loss : 0.013\n",
      "[113 / 200]\n",
      "epoch 113 avg loss : 0.012\n",
      "[114 / 200]\n",
      "epoch 114 avg loss : 0.012\n",
      "[115 / 200]\n",
      "epoch 115 avg loss : 0.013\n",
      "[116 / 200]\n",
      "epoch 116 avg loss : 0.012\n",
      "[117 / 200]\n",
      "epoch 117 avg loss : 0.012\n",
      "[118 / 200]\n",
      "epoch 118 avg loss : 0.011\n",
      "[119 / 200]\n",
      "epoch 119 avg loss : 0.012\n",
      "[120 / 200]\n",
      "epoch 120 avg loss : 0.012\n",
      "[121 / 200]\n",
      "epoch 121 avg loss : 0.011\n",
      "[122 / 200]\n",
      "epoch 122 avg loss : 0.012\n",
      "[123 / 200]\n",
      "epoch 123 avg loss : 0.012\n",
      "[124 / 200]\n",
      "epoch 124 avg loss : 0.013\n",
      "[125 / 200]\n",
      "epoch 125 avg loss : 0.013\n",
      "[126 / 200]\n",
      "epoch 126 avg loss : 0.011\n",
      "[127 / 200]\n",
      "epoch 127 avg loss : 0.011\n",
      "[128 / 200]\n",
      "epoch 128 avg loss : 0.012\n",
      "[129 / 200]\n",
      "epoch 129 avg loss : 0.011\n",
      "[130 / 200]\n",
      "epoch 130 avg loss : 0.012\n",
      "[131 / 200]\n",
      "epoch 131 avg loss : 0.011\n",
      "[132 / 200]\n",
      "epoch 132 avg loss : 0.011\n",
      "[133 / 200]\n",
      "epoch 133 avg loss : 0.012\n",
      "[134 / 200]\n",
      "epoch 134 avg loss : 0.012\n",
      "[135 / 200]\n",
      "epoch 135 avg loss : 0.012\n",
      "[136 / 200]\n",
      "epoch 136 avg loss : 0.012\n",
      "[137 / 200]\n",
      "epoch 137 avg loss : 0.012\n",
      "[138 / 200]\n",
      "epoch 138 avg loss : 0.012\n",
      "[139 / 200]\n",
      "epoch 139 avg loss : 0.011\n",
      "[140 / 200]\n",
      "epoch 140 avg loss : 0.011\n",
      "[141 / 200]\n",
      "epoch 141 avg loss : 0.011\n",
      "[142 / 200]\n",
      "epoch 142 avg loss : 0.011\n",
      "[143 / 200]\n",
      "epoch 143 avg loss : 0.010\n",
      "[144 / 200]\n",
      "epoch 144 avg loss : 0.011\n",
      "[145 / 200]\n",
      "epoch 145 avg loss : 0.011\n",
      "[146 / 200]\n",
      "epoch 146 avg loss : 0.012\n",
      "[147 / 200]\n",
      "epoch 147 avg loss : 0.011\n",
      "[148 / 200]\n",
      "epoch 148 avg loss : 0.010\n",
      "[149 / 200]\n",
      "epoch 149 avg loss : 0.012\n",
      "[150 / 200]\n",
      "epoch 150 avg loss : 0.013\n",
      "[151 / 200]\n",
      "epoch 151 avg loss : 0.012\n",
      "[152 / 200]\n",
      "epoch 152 avg loss : 0.011\n",
      "[153 / 200]\n",
      "epoch 153 avg loss : 0.011\n",
      "[154 / 200]\n",
      "epoch 154 avg loss : 0.011\n",
      "[155 / 200]\n",
      "epoch 155 avg loss : 0.011\n",
      "[156 / 200]\n",
      "epoch 156 avg loss : 0.010\n",
      "[157 / 200]\n",
      "epoch 157 avg loss : 0.010\n",
      "[158 / 200]\n",
      "epoch 158 avg loss : 0.011\n",
      "[159 / 200]\n",
      "epoch 159 avg loss : 0.011\n",
      "[160 / 200]\n",
      "epoch 160 avg loss : 0.011\n",
      "[161 / 200]\n",
      "epoch 161 avg loss : 0.011\n",
      "[162 / 200]\n",
      "epoch 162 avg loss : 0.010\n",
      "[163 / 200]\n",
      "epoch 163 avg loss : 0.010\n",
      "[164 / 200]\n",
      "epoch 164 avg loss : 0.011\n",
      "[165 / 200]\n",
      "epoch 165 avg loss : 0.011\n",
      "[166 / 200]\n",
      "epoch 166 avg loss : 0.011\n",
      "[167 / 200]\n",
      "epoch 167 avg loss : 0.013\n",
      "[168 / 200]\n",
      "epoch 168 avg loss : 0.014\n",
      "[169 / 200]\n",
      "epoch 169 avg loss : 0.011\n",
      "[170 / 200]\n",
      "epoch 170 avg loss : 0.011\n",
      "[171 / 200]\n",
      "epoch 171 avg loss : 0.011\n",
      "[172 / 200]\n",
      "epoch 172 avg loss : 0.010\n",
      "[173 / 200]\n",
      "epoch 173 avg loss : 0.010\n",
      "[174 / 200]\n",
      "epoch 174 avg loss : 0.011\n",
      "[175 / 200]\n",
      "epoch 175 avg loss : 0.011\n",
      "[176 / 200]\n",
      "epoch 176 avg loss : 0.011\n",
      "[177 / 200]\n",
      "epoch 177 avg loss : 0.010\n",
      "[178 / 200]\n",
      "epoch 178 avg loss : 0.011\n",
      "[179 / 200]\n",
      "epoch 179 avg loss : 0.010\n",
      "[180 / 200]\n",
      "epoch 180 avg loss : 0.010\n",
      "[181 / 200]\n",
      "epoch 181 avg loss : 0.011\n",
      "[182 / 200]\n",
      "epoch 182 avg loss : 0.011\n",
      "[183 / 200]\n",
      "epoch 183 avg loss : 0.010\n",
      "[184 / 200]\n",
      "epoch 184 avg loss : 0.010\n",
      "[185 / 200]\n",
      "epoch 185 avg loss : 0.010\n",
      "[186 / 200]\n",
      "epoch 186 avg loss : 0.011\n",
      "[187 / 200]\n",
      "epoch 187 avg loss : 0.011\n",
      "[188 / 200]\n",
      "epoch 188 avg loss : 0.011\n",
      "[189 / 200]\n",
      "epoch 189 avg loss : 0.010\n",
      "[190 / 200]\n",
      "epoch 190 avg loss : 0.009\n",
      "[191 / 200]\n",
      "epoch 191 avg loss : 0.010\n",
      "[192 / 200]\n",
      "epoch 192 avg loss : 0.010\n",
      "[193 / 200]\n",
      "epoch 193 avg loss : 0.010\n",
      "[194 / 200]\n",
      "epoch 194 avg loss : 0.011\n",
      "[195 / 200]\n",
      "epoch 195 avg loss : 0.010\n",
      "[196 / 200]\n",
      "epoch 196 avg loss : 0.010\n",
      "[197 / 200]\n",
      "epoch 197 avg loss : 0.011\n",
      "[198 / 200]\n",
      "epoch 198 avg loss : 0.010\n",
      "[199 / 200]\n",
      "epoch 199 avg loss : 0.010\n",
      "[200 / 200]\n",
      "epoch 200 avg loss : 0.009\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "    print(f'[{epoch} / {epochs}]')\n",
    "    model.train()\n",
    "    \n",
    "    loss, step = 0, 0\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        step += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        moving     = batch['moving_hand'].to(device)\n",
    "        fixed      = batch['fixed_hand'].to(device)\n",
    "        ddf        = model(torch.cat((moving, fixed), dim = 1))\n",
    "        pred_image = warp_layer(moving, ddf)\n",
    "        \n",
    "        loss_      = image_loss(pred_image, fixed)\n",
    "        loss_.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        loss += loss_.item()\n",
    "        \n",
    "    loss /= step\n",
    "    losses.append(loss)\n",
    "    print(f'epoch {epoch} avg loss : {loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854b911-1f3e-4acc-be1a-18d68addd42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
